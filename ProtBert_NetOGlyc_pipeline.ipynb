{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProtBert-NetOGlyc-pipeline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8GUM4gTPz7nC9e1JUB8wi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casblaauw/BertOGlyc/blob/main/ProtBert_NetOGlyc_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6LVoxB91de4"
      },
      "source": [
        "<b> Work in progress!</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AShyi3UWtDGe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from google.colab import files, drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psnlDUXXtdmG",
        "outputId": "d38f41dc-1feb-4f0a-97f8-da08a21cd8da"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd4aKhrt7gJi"
      },
      "source": [
        "Steps to build:\n",
        "- Receive input as list of strings of some kind (list, series, ???)\n",
        "- Filter out if above 4000 and display message\n",
        "- Add padding\n",
        "- Get embeddings\n",
        "- Run predictor model\n",
        "- Turn scores into predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzjLO9OU9mCE"
      },
      "source": [
        "<b> Define and load in model </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LloiB1580a_2"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels = 1024, out_channels = 32, kernel_size = 7, padding = 3) \n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "        self.conv2 = nn.Conv1d(in_channels = 32, out_channels = 2, kernel_size = 7, padding = 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ---- Layer 1\n",
        "        # conv1 needs (batch_size, in_channels/features, length/seq_len), so (64, 1024, 4000) \n",
        "        # and outputs (64, 32, 4000)\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        # ---- Process first layer's output\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # ---- Layer 2\n",
        "        # conv2 takes (64, 32, 4000) and outputs (64, 2, 4000)\n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCxWp2OE0gwv",
        "outputId": "988d2816-b6c0-4c95-eb90-75807b0873cc"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# params_path = '/content/drive/MyDrive/NetOGlyc/model_params_beta099999.pth'\n",
        "params_path = '/content/drive/MyDrive/NetOGlyc/model_params_loss30.pth'\n",
        "params = torch.load(params_path, map_location = device)\n",
        "model.load_state_dict(params)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv1d(1024, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (conv2): Conv1d(32, 2, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6XY_rTj9ncU"
      },
      "source": [
        "<b> Load embeddings to test </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Kk8RBw1pSF"
      },
      "source": [
        "# Temp data generation for testing\n",
        "zip_path = '/content/drive/MyDrive/NetOGlyc/embeddings_npy.zip'\n",
        "gene = 'O00391'\n",
        "with np.load(zip_path) as zip:\n",
        "  data = zip[f\"embeddings_{gene}\"]\n",
        "\n",
        "data = torch.Tensor([data.T])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X1xpeuZ75sf"
      },
      "source": [
        "# Load in info\n",
        "info = pd.read_csv('/content/drive/MyDrive/NetOGlyc/embeddings_info.txt', sep = '\\t', index_col = 'gene')\n",
        "info['sequence'] = info['sequence'].apply(list)\n",
        "info['label'] = info['label'].apply(lambda x: list(map(int, list(x))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icscntXIn5xQ"
      },
      "source": [
        "<b> Test model performance </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xqN-GUH8wU8"
      },
      "source": [
        "# Invividual gene labels\n",
        "with torch.no_grad():\n",
        "  with np.load(zip_path) as zip:\n",
        "    for gene in info.index:\n",
        "      # Get embeddings\n",
        "      embeddings = zip[f\"embeddings_{gene}\"]\n",
        "      embeddings = torch.Tensor([embeddings.T])\n",
        "\n",
        "      # Make predictions and get true values\n",
        "      scores = model(embeddings.float())\n",
        "      preds = torch.argmax(scores, 1).squeeze().numpy()\n",
        "      labels = np.array(info.loc[gene, 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUmva9S-iN5l"
      },
      "source": [
        "## Check performance on entire training set\n",
        "## Biased, as the model is trained on 80% of this, so don't use for finetuning.\n",
        "## Still reveals large-scale model performance trends.\n",
        "\n",
        "# Initialise performance tracking objects\n",
        "results = {}\n",
        "tp_counter = 0\n",
        "pos_counter = 0\n",
        "tn_counter = 0\n",
        "neg_counter = 0\n",
        "sites_bool = []\n",
        "\n",
        "# Start predicting\n",
        "with torch.no_grad():\n",
        "  with np.load(zip_path) as zip:\n",
        "    for gene in info.index:\n",
        "      # Get embeddings\n",
        "      embeddings = zip[f\"embeddings_{gene}\"]\n",
        "      embeddings = torch.Tensor([embeddings.T])\n",
        "\n",
        "      # Make predictions and get true values\n",
        "      scores = model(embeddings.float())\n",
        "      preds = torch.argmax(scores, 1).squeeze().numpy()\n",
        "      labels = np.array(info.loc[gene, 'label'])\n",
        "\n",
        "      # Compare preds to ground truth\n",
        "      overall_pred = labels == preds\n",
        "      pos_pred = labels[preds == 1] == preds[preds == 1]\n",
        "      neg_pred = labels[preds == 0] == preds[preds == 0]\n",
        "      sites_found = (labels[labels == 1] == preds[labels == 1]).tolist()\n",
        "      print(f\"Gene {gene}: {f'{sum(pos_pred)}/{len(pos_pred)}':^5} site preds correct, {f'{sum(neg_pred)}/{len(neg_pred)}':^9} non-site (+padding) correct. {f'{sum(sites_found)}/{len(sites_found)}':^5} sites recovered. Overall: {f'{sum(overall_pred)}/{len(overall_pred)}':^9}.\")\n",
        "      \n",
        "      # Save results\n",
        "      results[gene] = [labels, preds, pos_pred, neg_pred, overall_pred]\n",
        "      tp_counter += sum(pos_pred)\n",
        "      pos_counter += len(pos_pred)\n",
        "      tn_counter += sum(neg_pred)\n",
        "      neg_counter += len(neg_pred)\n",
        "      sites_bool += sites_found\n",
        "\n",
        "print('-'*50)\n",
        "print(f\"Total: {tp_counter}/{pos_counter} site preds correct, {tn_counter}/{neg_counter} non-site preds correct. {f'{sum(sites_bool)}/{len(sites_bool)}'} total sites recovered.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wulA4FclkvYi"
      },
      "source": [
        "## Other loop: puts into perspective # of S/T's correctly labeled\n",
        "# When interpreting, keep in mind: no guarantee that pred sites contains all true sites, \n",
        "# (although the model does seem to capture them pretty consistently when site predictions are highly weighted).\n",
        "# Also no guarantee that all pred sites are S/T, but that seems to be almost 100% in my experience, clearly extracted from embeddings.\n",
        "\n",
        "for key in results.keys():\n",
        "  print(key)\n",
        "  site_res = np.array(info.loc[key, 'sequence'])[results[key][0] == 1]\n",
        "  site_loc = np.where(results[key][0] == 1)\n",
        "  pred_res = np.array(info.loc[key, 'sequence'])[results[key][1] == 1]\n",
        "  pred_loc = np.where(results[key][1] == 1)\n",
        "  res_count = info.loc[key, 'sequence'].count('S') + info.loc[key, 'sequence'].count('T')\n",
        "  print(f\"True sites: {len(site_res)}, pred sites: {len(pred_res)}, S/T count: {res_count}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}